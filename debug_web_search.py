#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç½‘ç»œæœç´¢åŠŸèƒ½è°ƒè¯•è„šæœ¬

ç”¨äºè°ƒè¯•WebSearchToolçš„æœç´¢é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯Bing RSSæœç´¢è¿”å›0ç»“æœçš„é—®é¢˜
"""

import requests
import xml.etree.ElementTree as ET
import json
from urllib.parse import quote, urlencode


def debug_bing_rss_search(query="transformeræ˜¯ä»€ä¹ˆï¼Ÿ"):
    """
    è¯¦ç»†è°ƒè¯•Bing RSSæœç´¢åŠŸèƒ½
    """
    print("ğŸ” [è°ƒè¯•] Bing RSSæœç´¢è¯¦ç»†åˆ†æ")
    print("="*80)
    
    url = "https://www.bing.com/search"
    params = {"q": query, "format": "rss"}
    
    print(f"ğŸ“‹ è¯·æ±‚ä¿¡æ¯:")
    print(f"  URL: {url}")
    print(f"  å‚æ•°: {params}")
    print(f"  å®Œæ•´URL: {url}?{urlencode(params)}")
    
    try:
        # æ·»åŠ æ›´å¤šçš„è¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        
        response = requests.get(url, params=params, headers=headers, timeout=20)
        
        print(f"\nğŸ“¤ å“åº”ä¿¡æ¯:")
        print(f"  çŠ¶æ€ç : {response.status_code}")
        print(f"  Content-Type: {response.headers.get('Content-Type', 'N/A')}")
        print(f"  Content-Length: {response.headers.get('Content-Length', 'N/A')}")
        print(f"  Server: {response.headers.get('Server', 'N/A')}")
        print(f"  å“åº”é•¿åº¦: {len(response.text)} å­—ç¬¦")
        
        # ä¿å­˜å®Œæ•´å“åº”åˆ°æ–‡ä»¶ä»¥ä¾¿åˆ†æ
        with open("bing_response_debug.xml", "w", encoding="utf-8") as f:
            f.write(response.text)
        print(f"  ğŸ’¾ å®Œæ•´å“åº”å·²ä¿å­˜åˆ°: bing_response_debug.xml")
        
        print(f"\nğŸ“„ å“åº”å†…å®¹ (å®Œæ•´):")
        print("-" * 80)
        print(response.text)
        print("-" * 80)
        
        # å°è¯•è§£æXML
        print(f"\nğŸ”§ XMLè§£æåˆ†æ:")
        try:
            root = ET.fromstring(response.text)
            print(f"  âœ… XMLè§£ææˆåŠŸ")
            print(f"  æ ¹å…ƒç´ : {root.tag}")
            print(f"  æ ¹å…ƒç´ å±æ€§: {root.attrib}")
            
            # æ‰“å°å®Œæ•´çš„XMLç»“æ„
            print(f"\nğŸŒ³ XMLç»“æ„æ ‘:")
            def print_element(element, indent=0):
                spaces = "  " * indent
                print(f"{spaces}{element.tag}: {element.text[:100] if element.text else ''}")
                for child in element:
                    print_element(child, indent + 1)
            
            print_element(root)
            
            # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„å…ƒç´ 
            print(f"\nğŸ” æœç´¢å„ç§å¯èƒ½çš„å†…å®¹å…ƒç´ :")
            
            # å°è¯•ä¸åŒçš„XPathè¡¨è¾¾å¼
            xpath_patterns = [
                ".//item",
                ".//entry", 
                ".//result",
                ".//channel/item",
                ".//rss/channel/item",
                "./channel/item",
                ".//feed/entry"
            ]
            
            for pattern in xpath_patterns:
                items = root.findall(pattern)
                print(f"  {pattern}: æ‰¾åˆ° {len(items)} ä¸ªå…ƒç´ ")
                if len(items) > 0:
                    for i, item in enumerate(items[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                        print(f"    é¡¹ç›® {i+1}: {item.tag} - {item.text[:50] if item.text else ''}")
            
            # æŸ¥æ‰¾æ‰€æœ‰æ–‡æœ¬å†…å®¹
            print(f"\nğŸ“ æ‰€æœ‰åŒ…å«æ–‡æœ¬çš„å…ƒç´ :")
            for elem in root.iter():
                if elem.text and elem.text.strip():
                    print(f"  {elem.tag}: {elem.text.strip()[:100]}")
                    
        except ET.ParseError as e:
            print(f"  âŒ XMLè§£æå¤±è´¥: {e}")
            
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return None


def test_alternative_search_methods():
    """
    æµ‹è¯•å…¶ä»–æœç´¢æ–¹æ³•
    """
    print("\n" + "="*80)
    print("ğŸ”§ æµ‹è¯•æ›¿ä»£æœç´¢æ–¹æ³•")
    print("="*80)
    
    query = "Pythonæœºå™¨å­¦ä¹ åº“"
    
    # æ–¹æ³•1: ç›´æ¥HTMLæœç´¢
    print("\n1ï¸âƒ£ æµ‹è¯•Bing HTMLæœç´¢:")
    try:
        url = "https://www.bing.com/search"
        params = {"q": query}
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(url, params=params, headers=headers, timeout=20)
        print(f"  çŠ¶æ€ç : {response.status_code}")
        print(f"  å“åº”é•¿åº¦: {len(response.text)} å­—ç¬¦")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æœç´¢ç»“æœ
        if "li class" in response.text or "div class" in response.text:
            print(f"  âœ… åŒ…å«HTMLç»“æ„ï¼Œå¯èƒ½æœ‰æœç´¢ç»“æœ")
            # ä¿å­˜HTMLå“åº”
            with open("bing_html_debug.html", "w", encoding="utf-8") as f:
                f.write(response.text)
            print(f"  ğŸ’¾ HTMLå“åº”å·²ä¿å­˜åˆ°: bing_html_debug.html")
        else:
            print(f"  âŒ å“åº”å¼‚å¸¸ï¼Œå¯èƒ½è¢«é˜»æ­¢")
            
    except Exception as e:
        print(f"  âŒ HTMLæœç´¢å¤±è´¥: {e}")
    
    # æ–¹æ³•2: DuckDuckGoæœç´¢
    print("\n2ï¸âƒ£ æµ‹è¯•DuckDuckGoæœç´¢:")
    try:
        url = "https://api.duckduckgo.com/"
        params = {
            "q": query,
            "format": "json",
            "no_html": "1",
            "skip_disambig": "1"
        }
        
        response = requests.get(url, params=params, timeout=20)
        print(f"  çŠ¶æ€ç : {response.status_code}")
        
        data = response.json()
        print(f"  æŠ½è±¡ç»“æœ: {len(data.get('Abstract', ''))} å­—ç¬¦")
        print(f"  ç›¸å…³ä¸»é¢˜: {len(data.get('RelatedTopics', []))} ä¸ª")
        print(f"  å³æ—¶ç­”æ¡ˆ: {data.get('Answer', 'N/A')}")
        
        if data.get('RelatedTopics'):
            print(f"  âœ… æ‰¾åˆ°ç›¸å…³ä¸»é¢˜:")
            for i, topic in enumerate(data['RelatedTopics'][:3]):
                print(f"    {i+1}. {topic.get('Text', '')[:100]}")
                
    except Exception as e:
        print(f"  âŒ DuckDuckGoæœç´¢å¤±è´¥: {e}")


def test_fixed_web_search_tool():
    """
    æµ‹è¯•ä¿®å¤åçš„WebSearchTool
    """
    print("\n" + "="*80)
    print("ğŸ› ï¸ æµ‹è¯•ä¿®å¤çš„WebSearchToolå®ç°")
    print("="*80)
    
    class FixedWebSearchTool:
        def __init__(self, engine="bing", max_results=10):
            self.engine = engine
            self.max_results = max_results
        
        def search_bing_html(self, query: str) -> list:
            """
            ä½¿ç”¨HTMLè§£æçš„Bingæœç´¢ï¼ˆæ›´å¯é ï¼‰
            """
            print(f"ğŸŒ ä½¿ç”¨HTMLè§£ææœç´¢: {query}")
            
            try:
                import re
                from bs4 import BeautifulSoup
                
                url = "https://www.bing.com/search"
                params = {"q": query}
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                }
                
                response = requests.get(url, params=params, headers=headers, timeout=20)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.text, 'html.parser')
                
                results = []
                
                # æŸ¥æ‰¾æœç´¢ç»“æœå…ƒç´ 
                result_elements = soup.find_all(['li', 'div'], class_=re.compile(r'b_algo|b_result'))
                
                print(f"  æ‰¾åˆ°å€™é€‰ç»“æœå…ƒç´ : {len(result_elements)} ä¸ª")
                
                for element in result_elements[:self.max_results]:
                    title_elem = element.find(['h2', 'h3', 'a'])
                    desc_elem = element.find(['p', 'div'], class_=re.compile(r'b_caption|caption'))
                    
                    if title_elem:
                        title = title_elem.get_text(strip=True)
                        link = title_elem.get('href', '') if title_elem.name == 'a' else ''
                        if not link and title_elem.find('a'):
                            link = title_elem.find('a').get('href', '')
                        
                        description = desc_elem.get_text(strip=True) if desc_elem else ''
                        
                        if title and (link or description):
                            results.append({
                                'title': title,
                                'link': link,
                                'description': description
                            })
                
                print(f"  âœ… æˆåŠŸæå– {len(results)} ä¸ªç»“æœ")
                return results
                
            except ImportError:
                print("  âŒ éœ€è¦å®‰è£…BeautifulSoup: pip install beautifulsoup4")
                return []
            except Exception as e:
                print(f"  âŒ HTMLæœç´¢å¤±è´¥: {e}")
                return []
        
        def search_duckduckgo(self, query: str) -> list:
            """
            ä½¿ç”¨DuckDuckGo APIæœç´¢
            """
            print(f"ğŸ¦† ä½¿ç”¨DuckDuckGoæœç´¢: {query}")
            
            try:
                url = "https://api.duckduckgo.com/"
                params = {
                    "q": query,
                    "format": "json",
                    "no_html": "1",
                    "skip_disambig": "1"
                }
                
                response = requests.get(url, params=params, timeout=20)
                response.raise_for_status()
                
                data = response.json()
                results = []
                
                # ä»ç›¸å…³ä¸»é¢˜ä¸­æå–ç»“æœ
                for topic in data.get('RelatedTopics', [])[:self.max_results]:
                    if isinstance(topic, dict) and 'Text' in topic:
                        results.append({
                            'title': topic.get('Text', '')[:100],
                            'link': topic.get('FirstURL', ''),
                            'description': topic.get('Text', '')
                        })
                
                # å¦‚æœæœ‰æŠ½è±¡ä¿¡æ¯ä¹Ÿæ·»åŠ è¿›å»
                if data.get('Abstract'):
                    results.insert(0, {
                        'title': f"å…³äº {query}",
                        'link': data.get('AbstractURL', ''),
                        'description': data.get('Abstract', '')
                    })
                
                print(f"  âœ… æˆåŠŸæå– {len(results)} ä¸ªç»“æœ")
                return results
                
            except Exception as e:
                print(f"  âŒ DuckDuckGoæœç´¢å¤±è´¥: {e}")
                return []
        
        def forward(self, query: str) -> str:
            """
            æ‰§è¡Œæœç´¢å¹¶æ ¼å¼åŒ–ç»“æœ
            """
            print(f"\nğŸ” å¼€å§‹æœç´¢: {query}")
            
            # é¦–å…ˆå°è¯•DuckDuckGoï¼ˆæ›´ç¨³å®šï¼‰
            results = self.search_duckduckgo(query)
            
            # å¦‚æœDuckDuckGoæ²¡æœ‰ç»“æœï¼Œå°è¯•Bing HTML
            if not results:
                print("  ğŸ”„ å°è¯•Bing HTMLæœç´¢...")
                results = self.search_bing_html(query)
            
            if not results:
                return f"âŒ æœç´¢ '{query}' æ²¡æœ‰æ‰¾åˆ°ç»“æœ"
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            for i, result in enumerate(results, 1):
                formatted_result = f"{i}. **{result['title']}**"
                if result['link']:
                    formatted_result += f"\n   é“¾æ¥: {result['link']}"
                if result['description']:
                    formatted_result += f"\n   æè¿°: {result['description'][:200]}..."
                formatted_results.append(formatted_result)
            
            final_result = f"ğŸ” æœç´¢ '{query}' çš„ç»“æœ:\n\n" + "\n\n".join(formatted_results)
            
            print(f"\nâœ… æ ¼å¼åŒ–ç»“æœé•¿åº¦: {len(final_result)} å­—ç¬¦")
            print(f"ğŸ“„ ç»“æœé¢„è§ˆ:\n{final_result[:500]}...")
            
            return final_result
    
    # æµ‹è¯•ä¿®å¤çš„æœç´¢å·¥å…·
    tool = FixedWebSearchTool()
    result = tool.forward("Pythonæœºå™¨å­¦ä¹ åº“")
    
    print(f"\nğŸ¯ æœ€ç»ˆæœç´¢ç»“æœ:")
    print("="*80)
    print(result)
    print("="*80)


def main():
    """
    ä¸»è°ƒè¯•å‡½æ•°
    """
    print("ğŸ”§ ç½‘ç»œæœç´¢åŠŸèƒ½è°ƒè¯•å·¥å…·")
    print("="*80)
    
    # 1. è°ƒè¯•Bing RSSæœç´¢
    debug_bing_rss_search()
    
    # 2. æµ‹è¯•æ›¿ä»£æœç´¢æ–¹æ³•
    # test_alternative_search_methods()
    
    # 3. æµ‹è¯•ä¿®å¤çš„æœç´¢å·¥å…·
    # test_fixed_web_search_tool()
    
    print(f"\nâœ… è°ƒè¯•å®Œæˆï¼")
    print(f"ğŸ“ æ–‡ä»¶è¾“å‡º:")
    print(f"  - bing_response_debug.xml: Bing RSSå“åº”")
    print(f"  - bing_html_debug.html: Bing HTMLå“åº”")


if __name__ == "__main__":
    main() 